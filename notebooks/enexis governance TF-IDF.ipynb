{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0890ba85-abc0-4a6d-9d16-5ab213f3f9b1",
   "metadata": {},
   "source": [
    "# TF-IDF on the Governance Set\n",
    "This notebook runs TF-IDF on the governance data set. It combines analysis and learning, so there are a few things in this notebook that someone experienced in TF-IDF would not need. We leave it in, to show our learning steps.\n",
    "\n",
    "The learning part of this notebook is based on [TF-IDF Vectorizer scikit-learn](https://medium.com/@cmukesh8688/tf-idf-vectorizer-scikit-learn-dbc0244a911a) by Mukesh Chaudhary. We replicate their steps and build from there.\n",
    "\n",
    "Prerequisite: This notebook expects that the \"_Explore the Governance Data Set_\" notebook has created a clean data set in `CACHE_DIR`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3367b64-b505-4c11-9cf2-f4d612d3f22a",
   "metadata": {},
   "source": [
    "**braindump**\n",
    "\n",
    "* TF-idf van alle duurzaamheisdocument: haal je eruit wat de typische DV woorden zijn ten op zichte vban alle woorden. --> traingen met DV subset en dan running met ALL superset.\n",
    "\n",
    "* Onderscheid maken tussen documenten / clusteren: vectors maken van alle documenten; tfidf van ieder DV document apart t.o.v. alle DV documenten; klassificate *binnen* DV documenten; trainen alle DV docs; test tegen elk DV docui\n",
    "\n",
    "\n",
    "* anders: pak alleen woorden die echt uniek zijn voor DV set (uit de eerste stap dus); en alleen die neem je mee in de test stap; je reduceret de feature set tot de DV-unieke woorden. Hiermee k-means custering voeden.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a95aae-68a2-4a0f-a0f8-b9c054f45a3f",
   "metadata": {},
   "source": [
    "---\n",
    "## Dependencies and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a8290fa-e5f5-43d9-b670-fa22044b10ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "263bd0dd-6e06-48a1-9b2d-090dd09e53d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python==3.10.9\n",
      "scikit-learn==1.2.2\n",
      "pandas==2.0.1\n",
      "numpy==1.24.3\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import sys\n",
    "from pathlib import Path\n",
    "WRITE='w'\n",
    "READ_BINARY='rb'\n",
    "print(\"python=={}\".format(re.sub(r'\\s.*', '', sys.version)))\n",
    "\n",
    "from sklearn import __version__ as sklearn__version__\n",
    "print(f\"scikit-learn=={sklearn__version__}\")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "print(f\"pandas=={pd.__version__}\")\n",
    "\n",
    "import numpy as np\n",
    "print(f\"numpy=={np.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43b3ece-9636-4328-9573-e2d6877a39c9",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Loading\n",
    "All data was preprocessed by the \"_Explore the Governance Data Set_\" notebook, so our data loading steps here can be simplified. We don't have to worry about tokenization, stemming and stop words. It is still useful to have convencience functions and constants to make the rest of the code more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27c60927-1ab6-4814-8edb-8f9a82313c3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all text documents = /home/jovyan/jads/execute-enexis/cache/Governance/GM????????.txt\n"
     ]
    }
   ],
   "source": [
    "CACHE_DIR = Path('../cache/Governance').resolve()\n",
    "\n",
    "# The files containing the extracted text from the raw documents.\n",
    "GLOB_ALL_DOCUMENTS = str(CACHE_DIR) + '/GM????????.txt'\n",
    "\n",
    "GLOB_CA = str(CACHE_DIR) + '/GM????CA??.txt'\n",
    "GLOB_DV = str(CACHE_DIR) + '/GM????DV??.txt'\n",
    "GLOB_EX = str(CACHE_DIR) + '/GM????EX??.txt'\n",
    "GLOB_IK = str(CACHE_DIR) + '/GM????IK??.txt'\n",
    "GLOB_JS = str(CACHE_DIR) + '/GM????JS??.txt'\n",
    "GLOB_OB = str(CACHE_DIR) + '/GM????OB??.txt'\n",
    "GLOB_PB = str(CACHE_DIR) + '/GM????PB??.txt'\n",
    "GLOB_TV = str(CACHE_DIR) + '/GM????TV??.txt'\n",
    "GLOB_WS = str(CACHE_DIR) + '/GM????WS??.txt'\n",
    "\n",
    "# take a glob and make it iterable. We cannot use globs as objects, since these get\n",
    "# \"exhausted\" when you iterate over them.\n",
    "# https://stackoverflow.com/questions/51108256/how-to-take-a-pathname-string-with-wildcards-and-resolve-the-glob-with-pathlib\n",
    "def expand_glob(glob):\n",
    "    p = Path(glob)\n",
    "    return Path(p.parent).expanduser().glob(p.name)\n",
    "\n",
    "print(f\"all text documents = {GLOB_ALL_DOCUMENTS}\")\n",
    "\n",
    "def load_documents_as_string_array(glob):\n",
    "    return [file.read_text() for file in expand_glob(glob)]\n",
    "\n",
    "def document_names(glob):\n",
    "    return [file.stem for file in expand_glob(glob)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6551fc1a-2b91-4884-b771-a30cd07835f6",
   "metadata": {},
   "source": [
    "---\n",
    "## Replicate Mukesh' Vectorizers (with Adaptations)\n",
    "\n",
    "This section replicates [TF-IDF Vectorizer scikit-learn](https://medium.com/@cmukesh8688/tf-idf-vectorizer-scikit-learn-dbc0244a911a) by Mukesh Chaudhary for the sake of understanding their steps better. We don't use the initialisation parameters from the example. Using a `word` analyser is the default, for example. We pack the result into a Pandas dataframe so it looks nice, adorning the rows and columns with the document names and words used.\n",
    "\n",
    "We also keep the stop words by _not_ specifying a stop word list. A large part of why we plan on using TF-IDF is so that common words are automatically filtered. Thus, we don't specify `stop_words='english'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5ab8f1a-e074-4230-ac54-f043787946c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_names     = ['Doc1',             'Doc2']\n",
    "# to test its behaviour, you can try some alternatives\n",
    "# train_documents = ['The sky is blue. the the the the the the ', 'The sun is bright.']\n",
    "# train_documents = ['The sky is blue. sky sky sky sky sky sky ', 'The sun is bright.']\n",
    "train_documents = ['The sky is blue.', 'The sun is bright.']\n",
    "test_names      = ['Doc3',                         'Doc4']\n",
    "test_documents  = ['The sun in the sky is bright', 'We can see the shining sun, the bright sun.']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128f5c40-c16c-4eb4-a2a3-037759783bac",
   "metadata": {},
   "source": [
    "First, the count vectorizer. We train the vectorizer and build up the internal word list. Then we look at the generated word count matrix and take a peek at the internal vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5916c91-091e-42f8-933e-476aa4d7ed35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blue</th>\n",
       "      <th>bright</th>\n",
       "      <th>is</th>\n",
       "      <th>sky</th>\n",
       "      <th>sun</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      blue  bright  is  sky  sun  the\n",
       "Doc1     1       0   1    1    0    1\n",
       "Doc2     0       1   1    0    1    1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_vectorize_strings(index, strings):\n",
    "    # run the vectorizer on the data\n",
    "    vectorizer = CountVectorizer()\n",
    "    word_matrix = vectorizer.fit_transform(strings)\n",
    "    words_list = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # take the output and package it into various useful data frames\n",
    "    per_document    = pd.DataFrame(index=index, columns=words_list, data=word_matrix.toarray())\n",
    "    sum_over_corpus = pd.DataFrame(per_document.sum(), columns=['sum']).T\n",
    "\n",
    "    return vectorizer, per_document, sum_over_corpus\n",
    "\n",
    "count_vectorizer, count_per_document, count_sum_over_corpus = count_vectorize_strings(train_names, train_documents)\n",
    "\n",
    "# show the word count per document. This is just that: a word count for each\n",
    "# word in the vocabulary, counted for each document separately.\n",
    "\n",
    "count_per_document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d99759b3-38e2-443b-a854-46e3b2e7814c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blue</th>\n",
       "      <th>bright</th>\n",
       "      <th>is</th>\n",
       "      <th>sky</th>\n",
       "      <th>sun</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     blue  bright  is  sky  sun  the\n",
       "sum     1       1   2    1    1    2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the sum of word counts over the corpus\n",
    "\n",
    "count_sum_over_corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5264c58-b1d3-4b91-a3e6-3e54a9b3e870",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blue</th>\n",
       "      <th>bright</th>\n",
       "      <th>is</th>\n",
       "      <th>sky</th>\n",
       "      <th>sun</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vocabulary index</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  blue  bright  is  sky  sun  the\n",
       "vocabulary index     0       1   2    3    4    5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a peek at the internal word list of the vectorizer. The numbers are\n",
    "# internal indices into its private data structure. Not very useful for our\n",
    "# code, but still good to get some idea of how the vectorizer works internally.\n",
    "\n",
    "pd.DataFrame().from_dict(count_vectorizer.vocabulary_, orient='index', columns=['vocabulary index']).sort_values('vocabulary index').T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a95b653-d68b-43be-8b5c-2f4c520e96b4",
   "metadata": {},
   "source": [
    "Next, we explore the TF-IDF vectorizer, which internally consists of a [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer), followed by a [TfidfTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0016d27e-66b9-4a82-8eb9-439e221e83b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blue</th>\n",
       "      <th>bright</th>\n",
       "      <th>is</th>\n",
       "      <th>sky</th>\n",
       "      <th>sun</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc1</th>\n",
       "      <td>0.576152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409937</td>\n",
       "      <td>0.576152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.576152</td>\n",
       "      <td>0.409937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.576152</td>\n",
       "      <td>0.409937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          blue    bright        is       sky       sun       the\n",
       "Doc1  0.576152  0.000000  0.409937  0.576152  0.000000  0.409937\n",
       "Doc2  0.000000  0.576152  0.409937  0.000000  0.576152  0.409937"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tfidf_vectorize_strings(index, strings, max_df=1.0, max_features=None):\n",
    "    # run the vectorizer on the data\n",
    "    vectorizer = TfidfVectorizer(max_df=max_df, max_features=max_features)\n",
    "    word_matrix = vectorizer.fit_transform(strings)\n",
    "    words_list = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # take the output and package it into various useful data frames\n",
    "    matrix = pd.DataFrame(index=index, columns=words_list, data=word_matrix.toarray())\n",
    "    idf = pd.DataFrame(columns=words_list, data=[vectorizer.idf_])\n",
    "\n",
    "    return vectorizer, matrix, idf\n",
    "\n",
    "tfidf_vectorizer, tfidf_matrix, tfidf_idf = tfidf_vectorize_strings(train_names, train_documents)\n",
    "tfidf_matrix\n",
    "\n",
    "# XXX ask Marieke to explain why the numbers are not 0 for the stop words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "353b8126-be9f-46f7-a10b-32c51080e4f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blue</th>\n",
       "      <th>bright</th>\n",
       "      <th>is</th>\n",
       "      <th>sky</th>\n",
       "      <th>sun</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.405465</td>\n",
       "      <td>1.405465</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.405465</td>\n",
       "      <td>1.405465</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       blue    bright   is       sky       sun  the\n",
       "0  1.405465  1.405465  1.0  1.405465  1.405465  1.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f4b1b3-3a35-4e8f-8179-29dc79b0e438",
   "metadata": {},
   "source": [
    "### Stop Word Elimination with `max_df`\n",
    "We can control stop word elimination with the `max_df` parameter. Setting that value to `1.0` effectively disables stop word elimination. Any other value between 0.0 and 1.0 represents more or less strict stop word removal. The default value for `max_df` is 1.0, which essentially means \"keep all words\". If we try lowering `max_df`, the vectorizer starts eliminating words that do not have much information in them. We might try a value of 0.5, for example, and look at the resulting matrix and the list of words that were eliminated this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2471a2d6-17af-4cda-a741-7ab265328254",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blue</th>\n",
       "      <th>bright</th>\n",
       "      <th>sky</th>\n",
       "      <th>sun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc1</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          blue    bright       sky       sun\n",
       "Doc1  0.707107  0.000000  0.707107  0.000000\n",
       "Doc2  0.000000  0.707107  0.000000  0.707107"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer, tfidf_matrix, tfidf_idf = tfidf_vectorize_strings(train_names, train_documents, max_df=0.5)\n",
    "tfidf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d66cb5c7-47e5-41e5-a4f0-5a1c5a9e379e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is', 'the'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's have a quick peek at the stop word list that the vectorizer built up.\n",
    "\n",
    "tfidf_vectorizer.stop_words_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e93aea-0568-4e22-9ef5-11dc248fc7b5",
   "metadata": {},
   "source": [
    "Then the inference step, this does not modify the internal state of the vectorizer anymore. We reuse the structure of the data frames that we generated during training to make the new data frame more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7cc44da-0ab1-48a6-b546-fcfd08f11c38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blue</th>\n",
       "      <th>bright</th>\n",
       "      <th>is</th>\n",
       "      <th>sky</th>\n",
       "      <th>sun</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      blue  bright  is  sky  sun  the\n",
       "Doc3     0       1   1    1    1    2\n",
       "Doc4     0       1   0    0    2    2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we use the count vectorizer again, which does not have a stop word list\n",
    "# and thus will show values for \"the\" and \"is\". The TF-IDF vectorizer comes\n",
    "# after.\n",
    "\n",
    "count_vector = count_vectorizer.transform(test_documents)\n",
    "pd.DataFrame(index=test_names, columns=count_per_document.columns,\n",
    "             data=count_vector.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92459708-960b-43d7-af1c-ba2ddc388bd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blue</th>\n",
       "      <th>bright</th>\n",
       "      <th>sky</th>\n",
       "      <th>sun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.577350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.894427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      blue    bright      sky       sun\n",
       "Doc3   0.0  0.577350  0.57735  0.577350\n",
       "Doc4   0.0  0.447214  0.00000  0.894427"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and using the last TF-IDF vectorizer, which does have stop word elimination.\n",
    "\n",
    "tfidf_data = tfidf_vectorizer.transform(test_documents).todense()\n",
    "pd.DataFrame(index=test_names, columns=tfidf_matrix.columns,\n",
    "             data=tfidf_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d6fe17-423a-4f41-a76d-00898991b3c0",
   "metadata": {},
   "source": [
    "### Stop Word Elemination using `max_features`\n",
    "An alternative to using `max_df` is to use `max_features` to control stop word elimination. `max_features` sets an upper limit on the number of words in the vocabulary, ordered by term frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "347dad29-151c-48da-b97c-42336e52884b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc1</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            is       the\n",
       "Doc1  0.707107  0.707107\n",
       "Doc2  0.707107  0.707107"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer, tfidf_matrix, tfidf_idf = tfidf_vectorize_strings(train_names, train_documents, max_features=2)\n",
    "tfidf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4fc4fbd8-d6d8-4919-8df3-ae68dca98184",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blue', 'bright', 'sky', 'sun'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's have a quick peek at the stop word list that the vectorizer built up.\n",
    "\n",
    "tfidf_vectorizer.stop_words_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b17d5e-1977-4092-9e75-5e0d293dc356",
   "metadata": {},
   "source": [
    "... oh. So this gives us the _reverse_ of what we need. This shows that using term frequency for this purpose is not really useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1ce7fb-dcf6-4cfb-92ee-c3e737bbb56d",
   "metadata": {},
   "source": [
    "---\n",
    "## Apply Vectorizers to Governance Data Set\n",
    "With the howto replicated, we can now apply the same to our own data sets. We reimplement the methods here to rely on file globs rather than using string arrays. We could reduce the code duplication somewhat, but that's not really high priority at this stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05d2a606-3637-4188-aafc-2c5a6a576ace",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tfidf_vectorize(glob, max_df=1.0):\n",
    "    # run the vectorizer on the data\n",
    "    vectorizer = TfidfVectorizer(max_df=max_df)\n",
    "    word_matrix = vectorizer.fit_transform(load_documents_as_string_array(glob))\n",
    "    words_list = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # take the output and package it into various useful data frames\n",
    "    matrix = pd.DataFrame(index=document_names(glob), columns=words_list, data=word_matrix.toarray())\n",
    "    idf = pd.DataFrame(columns=words_list, data=[vectorizer.idf_])\n",
    "\n",
    "    return vectorizer, matrix, idf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a264b28-fcd4-4eb7-bc67-c952a6a31a39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aaaaccommodaties</th>\n",
       "      <th>aaaactieprogramma</th>\n",
       "      <th>aaaactiva</th>\n",
       "      <th>aaaaf</th>\n",
       "      <th>aaaafkortingenlijst</th>\n",
       "      <th>aaaafval</th>\n",
       "      <th>aaaafvalstoff</th>\n",
       "      <th>aaaalgemen</th>\n",
       "      <th>aaaann</th>\n",
       "      <th>...</th>\n",
       "      <th>èffeoturer</th>\n",
       "      <th>èii</th>\n",
       "      <th>èlèèmnn</th>\n",
       "      <th>èmd</th>\n",
       "      <th>èmjim</th>\n",
       "      <th>ères</th>\n",
       "      <th>èàca</th>\n",
       "      <th>èàcaa</th>\n",
       "      <th>èèn</th>\n",
       "      <th>èèè</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GM0003DV02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM0003EX06</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM0003OB01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM0003OB02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM0005CA01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM1987DV01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM1987IK01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM1987JS01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM1987PB01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM1987TV01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2276 rows × 220927 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            aaaa  aaaaccommodaties  aaaactieprogramma  aaaactiva  aaaaf   \n",
       "GM0003DV02   0.0               0.0                0.0        0.0    0.0  \\\n",
       "GM0003EX06   0.0               0.0                0.0        0.0    0.0   \n",
       "GM0003OB01   0.0               0.0                0.0        0.0    0.0   \n",
       "GM0003OB02   0.0               0.0                0.0        0.0    0.0   \n",
       "GM0005CA01   0.0               0.0                0.0        0.0    0.0   \n",
       "...          ...               ...                ...        ...    ...   \n",
       "GM1987DV01   0.0               0.0                0.0        0.0    0.0   \n",
       "GM1987IK01   0.0               0.0                0.0        0.0    0.0   \n",
       "GM1987JS01   0.0               0.0                0.0        0.0    0.0   \n",
       "GM1987PB01   0.0               0.0                0.0        0.0    0.0   \n",
       "GM1987TV01   0.0               0.0                0.0        0.0    0.0   \n",
       "\n",
       "            aaaafkortingenlijst  aaaafval  aaaafvalstoff  aaaalgemen  aaaann   \n",
       "GM0003DV02                  0.0       0.0            0.0         0.0     0.0  \\\n",
       "GM0003EX06                  0.0       0.0            0.0         0.0     0.0   \n",
       "GM0003OB01                  0.0       0.0            0.0         0.0     0.0   \n",
       "GM0003OB02                  0.0       0.0            0.0         0.0     0.0   \n",
       "GM0005CA01                  0.0       0.0            0.0         0.0     0.0   \n",
       "...                         ...       ...            ...         ...     ...   \n",
       "GM1987DV01                  0.0       0.0            0.0         0.0     0.0   \n",
       "GM1987IK01                  0.0       0.0            0.0         0.0     0.0   \n",
       "GM1987JS01                  0.0       0.0            0.0         0.0     0.0   \n",
       "GM1987PB01                  0.0       0.0            0.0         0.0     0.0   \n",
       "GM1987TV01                  0.0       0.0            0.0         0.0     0.0   \n",
       "\n",
       "            ...  èffeoturer  èii  èlèèmnn  èmd  èmjim  ères  èàca  èàcaa  èèn   \n",
       "GM0003DV02  ...         0.0  0.0      0.0  0.0    0.0   0.0   0.0    0.0  0.0  \\\n",
       "GM0003EX06  ...         0.0  0.0      0.0  0.0    0.0   0.0   0.0    0.0  0.0   \n",
       "GM0003OB01  ...         0.0  0.0      0.0  0.0    0.0   0.0   0.0    0.0  0.0   \n",
       "GM0003OB02  ...         0.0  0.0      0.0  0.0    0.0   0.0   0.0    0.0  0.0   \n",
       "GM0005CA01  ...         0.0  0.0      0.0  0.0    0.0   0.0   0.0    0.0  0.0   \n",
       "...         ...         ...  ...      ...  ...    ...   ...   ...    ...  ...   \n",
       "GM1987DV01  ...         0.0  0.0      0.0  0.0    0.0   0.0   0.0    0.0  0.0   \n",
       "GM1987IK01  ...         0.0  0.0      0.0  0.0    0.0   0.0   0.0    0.0  0.0   \n",
       "GM1987JS01  ...         0.0  0.0      0.0  0.0    0.0   0.0   0.0    0.0  0.0   \n",
       "GM1987PB01  ...         0.0  0.0      0.0  0.0    0.0   0.0   0.0    0.0  0.0   \n",
       "GM1987TV01  ...         0.0  0.0      0.0  0.0    0.0   0.0   0.0    0.0  0.0   \n",
       "\n",
       "            èèè  \n",
       "GM0003DV02  0.0  \n",
       "GM0003EX06  0.0  \n",
       "GM0003OB01  0.0  \n",
       "GM0003OB02  0.0  \n",
       "GM0005CA01  0.0  \n",
       "...         ...  \n",
       "GM1987DV01  0.0  \n",
       "GM1987IK01  0.0  \n",
       "GM1987JS01  0.0  \n",
       "GM1987PB01  0.0  \n",
       "GM1987TV01  0.0  \n",
       "\n",
       "[2276 rows x 220927 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_docs_vectorizer, all_docs_matrix, all_docs_idf = tfidf_vectorize(GLOB_ALL_DOCUMENTS, max_df=0.01)\n",
    "all_docs_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d10725c8-b7a9-43a9-8ff9-a0a94378f9cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18733"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all_docs_vectorizer.stop_words_\n",
    "len(all_docs_vectorizer.stop_words_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b867680-dfde-4148-8053-9ad0c31054ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aab</th>\n",
       "      <th>aachener</th>\n",
       "      <th>aadefg</th>\n",
       "      <th>aadijk</th>\n",
       "      <th>aak</th>\n",
       "      <th>aalburg</th>\n",
       "      <th>aalderveld</th>\n",
       "      <th>aalscholver</th>\n",
       "      <th>aalsmeerder</th>\n",
       "      <th>aalst</th>\n",
       "      <th>...</th>\n",
       "      <th>zwollenar</th>\n",
       "      <th>zwoud</th>\n",
       "      <th>zzh</th>\n",
       "      <th>zzprs</th>\n",
       "      <th>zzzzzzz</th>\n",
       "      <th>zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz</th>\n",
       "      <th>zèlf</th>\n",
       "      <th>àlle</th>\n",
       "      <th>ànciew</th>\n",
       "      <th>ècht</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GM0003DV02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM0005DV01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM0007DV01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM0009DV01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM0034DV01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM1945DV01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM1955DV01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM1955DV02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM1955DV03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM1987DV01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251 rows × 32043 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            aab  aachener  aadefg  aadijk  aak  aalburg  aalderveld   \n",
       "GM0003DV02  0.0       0.0     0.0     0.0  0.0      0.0         0.0  \\\n",
       "GM0005DV01  0.0       0.0     0.0     0.0  0.0      0.0         0.0   \n",
       "GM0007DV01  0.0       0.0     0.0     0.0  0.0      0.0         0.0   \n",
       "GM0009DV01  0.0       0.0     0.0     0.0  0.0      0.0         0.0   \n",
       "GM0034DV01  0.0       0.0     0.0     0.0  0.0      0.0         0.0   \n",
       "...         ...       ...     ...     ...  ...      ...         ...   \n",
       "GM1945DV01  0.0       0.0     0.0     0.0  0.0      0.0         0.0   \n",
       "GM1955DV01  0.0       0.0     0.0     0.0  0.0      0.0         0.0   \n",
       "GM1955DV02  0.0       0.0     0.0     0.0  0.0      0.0         0.0   \n",
       "GM1955DV03  0.0       0.0     0.0     0.0  0.0      0.0         0.0   \n",
       "GM1987DV01  0.0       0.0     0.0     0.0  0.0      0.0         0.0   \n",
       "\n",
       "            aalscholver  aalsmeerder  aalst  ...  zwollenar  zwoud  zzh   \n",
       "GM0003DV02          0.0          0.0    0.0  ...        0.0    0.0  0.0  \\\n",
       "GM0005DV01          0.0          0.0    0.0  ...        0.0    0.0  0.0   \n",
       "GM0007DV01          0.0          0.0    0.0  ...        0.0    0.0  0.0   \n",
       "GM0009DV01          0.0          0.0    0.0  ...        0.0    0.0  0.0   \n",
       "GM0034DV01          0.0          0.0    0.0  ...        0.0    0.0  0.0   \n",
       "...                 ...          ...    ...  ...        ...    ...  ...   \n",
       "GM1945DV01          0.0          0.0    0.0  ...        0.0    0.0  0.0   \n",
       "GM1955DV01          0.0          0.0    0.0  ...        0.0    0.0  0.0   \n",
       "GM1955DV02          0.0          0.0    0.0  ...        0.0    0.0  0.0   \n",
       "GM1955DV03          0.0          0.0    0.0  ...        0.0    0.0  0.0   \n",
       "GM1987DV01          0.0          0.0    0.0  ...        0.0    0.0  0.0   \n",
       "\n",
       "            zzprs  zzzzzzz  zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz  zèlf   \n",
       "GM0003DV02    0.0      0.0                                       0.0   0.0  \\\n",
       "GM0005DV01    0.0      0.0                                       0.0   0.0   \n",
       "GM0007DV01    0.0      0.0                                       0.0   0.0   \n",
       "GM0009DV01    0.0      0.0                                       0.0   0.0   \n",
       "GM0034DV01    0.0      0.0                                       0.0   0.0   \n",
       "...           ...      ...                                       ...   ...   \n",
       "GM1945DV01    0.0      0.0                                       0.0   0.0   \n",
       "GM1955DV01    0.0      0.0                                       0.0   0.0   \n",
       "GM1955DV02    0.0      0.0                                       0.0   0.0   \n",
       "GM1955DV03    0.0      0.0                                       0.0   0.0   \n",
       "GM1987DV01    0.0      0.0                                       0.0   0.0   \n",
       "\n",
       "            àlle  ànciew  ècht  \n",
       "GM0003DV02   0.0     0.0   0.0  \n",
       "GM0005DV01   0.0     0.0   0.0  \n",
       "GM0007DV01   0.0     0.0   0.0  \n",
       "GM0009DV01   0.0     0.0   0.0  \n",
       "GM0034DV01   0.0     0.0   0.0  \n",
       "...          ...     ...   ...  \n",
       "GM1945DV01   0.0     0.0   0.0  \n",
       "GM1955DV01   0.0     0.0   0.0  \n",
       "GM1955DV02   0.0     0.0   0.0  \n",
       "GM1955DV03   0.0     0.0   0.0  \n",
       "GM1987DV01   0.0     0.0   0.0  \n",
       "\n",
       "[251 rows x 32043 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv_docs_vectorizer, dv_docs_matrix, dv_docs_idf = tfidf_vectorize(GLOB_DV, max_df=0.01)\n",
    "dv_docs_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a3d6581-5eac-47dd-be46-46444868493a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14343"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dv_docs_vectorizer.stop_words_#\n",
    "len(dv_docs_vectorizer.stop_words_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5215b0f5-f35c-4b58-8152-c6e510e2fa82",
   "metadata": {},
   "source": [
    "---\n",
    "## Cross Referencing Data Sets\n",
    "Now try training on one set and running on the other. Run the `all_docs_vectorizer` on the DV data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e8d9b92-2047-4036-884b-614130dd0252",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_vs_dv_matrix = all_docs_vectorizer.transform(load_documents_as_string_array(GLOB_DV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "130e42ef-9fc3-4294-992c-d39982f291fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aaaaccommodaties</th>\n",
       "      <th>aaaactieprogramma</th>\n",
       "      <th>aaaactiva</th>\n",
       "      <th>aaaaf</th>\n",
       "      <th>aaaafkortingenlijst</th>\n",
       "      <th>aaaafval</th>\n",
       "      <th>aaaafvalstoff</th>\n",
       "      <th>aaaalgemen</th>\n",
       "      <th>...</th>\n",
       "      <th>èffeoturer</th>\n",
       "      <th>èii</th>\n",
       "      <th>èlèèmnn</th>\n",
       "      <th>èmd</th>\n",
       "      <th>èmjim</th>\n",
       "      <th>ères</th>\n",
       "      <th>èàca</th>\n",
       "      <th>èàcaa</th>\n",
       "      <th>èèn</th>\n",
       "      <th>èèè</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GM0003DV02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM0005DV01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM0007DV01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM0009DV01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM0034DV01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM1945DV01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM1955DV01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM1955DV02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM1955DV03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM1987DV01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251 rows × 239009 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            aaa  aaaa  aaaaccommodaties  aaaactieprogramma  aaaactiva  aaaaf   \n",
       "GM0003DV02  0.0   0.0               0.0                0.0        0.0    0.0  \\\n",
       "GM0005DV01  0.0   0.0               0.0                0.0        0.0    0.0   \n",
       "GM0007DV01  0.0   0.0               0.0                0.0        0.0    0.0   \n",
       "GM0009DV01  0.0   0.0               0.0                0.0        0.0    0.0   \n",
       "GM0034DV01  0.0   0.0               0.0                0.0        0.0    0.0   \n",
       "...         ...   ...               ...                ...        ...    ...   \n",
       "GM1945DV01  0.0   0.0               0.0                0.0        0.0    0.0   \n",
       "GM1955DV01  0.0   0.0               0.0                0.0        0.0    0.0   \n",
       "GM1955DV02  0.0   0.0               0.0                0.0        0.0    0.0   \n",
       "GM1955DV03  0.0   0.0               0.0                0.0        0.0    0.0   \n",
       "GM1987DV01  0.0   0.0               0.0                0.0        0.0    0.0   \n",
       "\n",
       "            aaaafkortingenlijst  aaaafval  aaaafvalstoff  aaaalgemen  ...   \n",
       "GM0003DV02                  0.0       0.0            0.0         0.0  ...  \\\n",
       "GM0005DV01                  0.0       0.0            0.0         0.0  ...   \n",
       "GM0007DV01                  0.0       0.0            0.0         0.0  ...   \n",
       "GM0009DV01                  0.0       0.0            0.0         0.0  ...   \n",
       "GM0034DV01                  0.0       0.0            0.0         0.0  ...   \n",
       "...                         ...       ...            ...         ...  ...   \n",
       "GM1945DV01                  0.0       0.0            0.0         0.0  ...   \n",
       "GM1955DV01                  0.0       0.0            0.0         0.0  ...   \n",
       "GM1955DV02                  0.0       0.0            0.0         0.0  ...   \n",
       "GM1955DV03                  0.0       0.0            0.0         0.0  ...   \n",
       "GM1987DV01                  0.0       0.0            0.0         0.0  ...   \n",
       "\n",
       "            èffeoturer  èii  èlèèmnn  èmd  èmjim  ères  èàca  èàcaa  èèn  èèè  \n",
       "GM0003DV02         0.0  0.0      0.0  0.0    0.0   0.0   0.0    0.0  0.0  0.0  \n",
       "GM0005DV01         0.0  0.0      0.0  0.0    0.0   0.0   0.0    0.0  0.0  0.0  \n",
       "GM0007DV01         0.0  0.0      0.0  0.0    0.0   0.0   0.0    0.0  0.0  0.0  \n",
       "GM0009DV01         0.0  0.0      0.0  0.0    0.0   0.0   0.0    0.0  0.0  0.0  \n",
       "GM0034DV01         0.0  0.0      0.0  0.0    0.0   0.0   0.0    0.0  0.0  0.0  \n",
       "...                ...  ...      ...  ...    ...   ...   ...    ...  ...  ...  \n",
       "GM1945DV01         0.0  0.0      0.0  0.0    0.0   0.0   0.0    0.0  0.0  0.0  \n",
       "GM1955DV01         0.0  0.0      0.0  0.0    0.0   0.0   0.0    0.0  0.0  0.0  \n",
       "GM1955DV02         0.0  0.0      0.0  0.0    0.0   0.0   0.0    0.0  0.0  0.0  \n",
       "GM1955DV03         0.0  0.0      0.0  0.0    0.0   0.0   0.0    0.0  0.0  0.0  \n",
       "GM1987DV01         0.0  0.0      0.0  0.0    0.0   0.0   0.0    0.0  0.0  0.0  \n",
       "\n",
       "[251 rows x 239009 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(index=document_names(GLOB_DV), columns=all_docs_vectorizer.get_feature_names_out(), data=all_vs_dv_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f423dd92-f725-48ab-bf9a-ffa9a8977eed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
